{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c98e37-0530-42c1-a1b7-65701a89d16e",
   "metadata": {},
   "source": [
    "# 1-Canny edge detection\n",
    "## gaussian and first derivative based\n",
    "#### gray->blur->gradiet(sobel)->non maximum suppression(using gradient magnitude and gradient direction)->double thresholding   ->hysteresis thresholding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "25f0722a-4318-40c4-b7c1-2da5a135e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2b79edd5-47f9-490b-918d-6c3ef2bc1612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "742b3f5b-b03c-4e48-8f8c-3e3c003ae237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(gradient_magnitude, gradient_direction):\n",
    "    M, N = gradient_magnitude.shape\n",
    "    result = np.zeros_like(gradient_magnitude)\n",
    "    for i in range(1, M-1):\n",
    "        for j in range(1, N-1):\n",
    "            direction = gradient_direction[i, j] * 180 / np.pi\n",
    "            if 0 <= direction < 22.5 or 157.5 <= direction <= 180:\n",
    "                neighbor1, neighbor2 = gradient_magnitude[i, j+1], gradient_magnitude[i, j-1]\n",
    "            elif 22.5 <= direction < 67.5:\n",
    "                neighbor1, neighbor2 = gradient_magnitude[i+1, j+1], gradient_magnitude[i-1, j-1]\n",
    "            elif 67.5 <= direction < 112.5:\n",
    "                neighbor1, neighbor2 = gradient_magnitude[i+1, j], gradient_magnitude[i-1, j]\n",
    "            else:\n",
    "                neighbor1, neighbor2 = gradient_magnitude[i+1, j-1], gradient_magnitude[i-1, j+1]\n",
    "            if gradient_magnitude[i, j] >= neighbor1 and gradient_magnitude[i, j] >= neighbor2:\n",
    "                result[i, j] = gradient_magnitude[i, j]\n",
    "    return result\n",
    "\n",
    "# we look for nearby pixels in a pixels kernel(3 by 3) in the direction of gradient and if the next pixel has higher intensity then it makes itself 0(black) else retains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4f14c0b9-2267-4b78-b54a-3da0d818b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_thresholding(image, high_threshold, low_threshold):\n",
    "    result = np.zeros_like(image)\n",
    "    strong_edges = image > high_threshold\n",
    "    weak_edges = (image > low_threshold) & (image <= high_threshold)\n",
    "    result[strong_edges] = 255\n",
    "    result[weak_edges] = 128\n",
    "    return result\n",
    "\n",
    "#sets strong and weak edges for a given threshold range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ea166a01-3bd9-47e3-baa2-bfa7a3be8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hysteresis_thresholding(image):\n",
    "    result = np.copy(image)\n",
    "    for i in range(1, image.shape[0] - 1):\n",
    "        for j in range(1, image.shape[1] - 1):\n",
    "            if image[i, j] == 128:\n",
    "                if (image[i+1, j] == 255) or (image[i-1, j] == 255) or (image[i, j+1] == 255) or (image[i, j-1] == 255) or (image[i+1, j+1] == 255) or (image[i-1, j-1] == 255) or (image[i+1, j-1] == 255) or (image[i-1, j+1] == 255):\n",
    "                    result[i, j] = 255\n",
    "                else:\n",
    "                    result[i, j] = 0\n",
    "    return result\n",
    "\n",
    "# weak edges are retained only when they are connected to strong edges otherwise set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a44f3ab0-2928-4e20-96c6-ca8420640568",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv.imread(r\"C:\\Users\\chinm\\Desktop\\sem_3\\ieeeMl\\jupNb\\resources\\car.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c3fe1367-88ef-479a-80cc-011e285dd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray=cv.cvtColor(img,cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8e1667bf-2f0d-45bc-ab6b-0f2f61b045a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss=cv.GaussianBlur(gray,(3,5),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fdd025ff-f83e-46db-b283-404f5d13adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobelx=cv.Sobel(gauss,cv.CV_64F,1,0)\n",
    "sobely=cv.Sobel(gauss,cv.CV_64F,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "afa56876-bab4-469c-ac58-26e784571f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "gradient_direction = np.arctan2(sobely, sobelx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7130dd1a-1c09-4baa-8581-9280e7752c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_max_suppressed = non_max_suppression(gradient_magnitude, gradient_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f5f23615-6758-4a91-87b0-185cf2dbfd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_image = double_thresholding(non_max_suppressed, 200, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "00c74e1b-d191-41f0-ba15-ec55eca2964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hysteresis_threshold=hysteresis_thresholding(thresholded_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f4cf311f-a2a4-47c4-ab02-345a05cc7f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canny =cv.Canny(img,190,220)\n",
    "cv.imshow('hysteresis_threshold',hysteresis_threshold)\n",
    "cv.imshow('canny',canny)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cfcfa-e800-4f0a-b107-384bd119943f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17746be-1fca-4a64-94cc-f64462001ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1eb9cbad-4aa7-4fe2-9171-0fbffec7714c",
   "metadata": {},
   "source": [
    "# 2-Sobel Edge Detection\n",
    "## second derivative and gaussian based\n",
    "#### blurredAndGrayscaledImage->define sobel kernels->apply convolution to get gradient->thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2145a020-3ad8-40bb-84da-0fd75b480458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_edge_detection(image, threshold):\n",
    "    kernel_x = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
    "    kernel_y = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]\n",
    "    edge_map=np.zeros_like(image)\n",
    "    for y in range(1, len(image) - 1):\n",
    "        for x in range(1, len(image[0]) - 1):\n",
    "            gx = (kernel_x[0][0] * image[y - 1][x - 1]) + \\\n",
    "                 (kernel_x[0][1] * image[y - 1][x]) + \\\n",
    "                 (kernel_x[0][2] * image[y - 1][x + 1]) + \\\n",
    "                 (kernel_x[1][0] * image[y][x - 1]) + \\\n",
    "                 (kernel_x[1][1] * image[y][x]) + \\\n",
    "                 (kernel_x[1][2] * image[y][x + 1]) + \\\n",
    "                 (kernel_x[2][0] * image[y + 1][x - 1]) + \\\n",
    "                 (kernel_x[2][1] * image[y + 1][x]) + \\\n",
    "                 (kernel_x[2][2] * image[y + 1][x + 1])\n",
    "            gy = (kernel_y[0][0] * image[y - 1][x - 1]) + \\\n",
    "                 (kernel_y[0][1] * image[y - 1][x]) + \\\n",
    "                 (kernel_y[0][2] * image[y - 1][x + 1]) + \\\n",
    "                 (kernel_y[1][0] * image[y][x - 1]) + \\\n",
    "                 (kernel_y[1][1] * image[y][x]) + \\\n",
    "                 (kernel_y[1][2] * image[y][x + 1]) + \\\n",
    "                 (kernel_y[2][0] * image[y + 1][x - 1]) + \\\n",
    "                 (kernel_y[2][1] * image[y + 1][x]) + \\\n",
    "                 (kernel_y[2][2] * image[y + 1][x + 1])\n",
    "            magnitude = (gx**2 + gy**2)**0.5\n",
    "            edge_map[y][x] = 255 if magnitude > threshold else 0\n",
    "    edge_map = np.array(edge_map, dtype=np.uint8)\n",
    "    return edge_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "35c78d03-be2a-4720-89cb-c4b67163d313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image=sobel_edge_detection(gauss,150)\n",
    "cv.imshow('sobel',image)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62652ae6-343f-4edf-acaf-06386155de57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
